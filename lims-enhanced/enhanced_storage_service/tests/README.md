# Enhanced Storage Service - Comprehensive Test Suite

## Overview
This test suite provides comprehensive coverage for the Enhanced Storage Service, including:
- **Storage Management**: Location and sample operations
- **IoT Integration**: Sensor monitoring and data collection
- **Blockchain**: Chain of custody and audit trails
- **Analytics**: Predictive models and data analysis
- **Automation**: Robotic operations and workflows
- **Energy Management**: Consumption monitoring and optimization
- **Mobile Integration**: Mobile app support
- **Compliance**: Regulatory compliance tracking
- **AI/ML Platform**: Machine learning capabilities
- **Enterprise Integration**: LIMS, ERP, and cloud integrations

## Test Structure

```
tests/
â”œâ”€â”€ lib.rs                    # Test library configuration
â”œâ”€â”€ test_utils.rs            # Test utilities and database setup
â”œâ”€â”€ fixtures.rs              # Test data fixtures
â”œâ”€â”€ unit/                    # Unit tests for individual components
â”‚   â”œâ”€â”€ test_storage_handlers.rs
â”‚   â”œâ”€â”€ test_iot_handlers.rs
â”‚   â””â”€â”€ test_health_handlers.rs
â”œâ”€â”€ integration/             # Integration tests for workflows
â”‚   â”œâ”€â”€ test_database_operations.rs
â”‚   â””â”€â”€ test_iot_workflows.rs
â”œâ”€â”€ end_to_end/             # End-to-end workflow tests
â”‚   â””â”€â”€ test_complete_workflows.rs
â”œâ”€â”€ performance/            # Performance and load tests
â”œâ”€â”€ security/              # Security and penetration tests
â””â”€â”€ README.md              # This file
```

## Test Categories

### Unit Tests
- **Storage Handlers**: CRUD operations for locations and samples
- **IoT Handlers**: Sensor registration, data recording, alerts
- **Health Handlers**: Health checks, readiness, metrics
- **Validation**: Input validation and error handling

### Integration Tests
- **Database Operations**: Transaction handling, constraints
- **Service Communication**: Inter-service calls and workflows
- **IoT Workflows**: Complete sensor monitoring cycles
- **Analytics Workflows**: Predictive analytics and reporting

### End-to-End Tests
- **Complete Sample Lifecycle**: From storage to retrieval
- **IoT Monitoring Workflow**: Sensor registration to alerting
- **Capacity Management**: Storage optimization workflows
- **Error Handling**: Comprehensive error scenarios

## Test Features

### Database Testing
- **Isolated Test Databases**: Each test gets a clean database
- **Transaction Testing**: Rollback scenarios and data consistency
- **Constraint Testing**: Foreign key and validation constraints
- **Concurrent Access**: Multi-threaded database operations

### Mock Services
- **AI Platform**: Mocked machine learning services
- **Integration Hub**: Mocked external integrations
- **IoT Sensors**: Simulated sensor readings and alerts

### Test Utilities
- **TestDatabase**: Automatic database creation and cleanup
- **TestDataFactory**: Consistent test data generation
- **TestAssertions**: Common assertion patterns
- **TestClient**: HTTP client for API testing

## Running Tests

### Prerequisites
Set up test database connection:
```bash
export TEST_DATABASE_URL="postgresql://postgres:password@localhost:5432/postgres"
```

### Run All Tests
```bash
cargo test --tests
```

### Run Specific Test Categories
```bash
# Unit tests only
cargo test --tests unit

# Integration tests only
cargo test --tests integration

# End-to-end tests only
cargo test --tests end_to_end

# Specific test file
cargo test --tests test_storage_handlers
```

### Run Tests with Logging
```bash
RUST_LOG=debug cargo test --tests -- --nocapture
```

### Run Tests Sequentially (for database-intensive tests)
```bash
cargo test --tests -- --test-threads=1
```

## Test Configuration

### Environment Variables
- `TEST_DATABASE_URL`: PostgreSQL connection for tests
- `RUST_LOG`: Logging level for test execution
- `TEST_TIMEOUT`: Timeout for individual tests (default: 60s)

### Test Database
- Each test gets an isolated PostgreSQL database
- Databases are automatically created and cleaned up
- Schema migrations are applied automatically
- Foreign key constraints are enforced

## Test Data Management

### Fixtures
- **StorageLocationFixtures**: Test storage locations
- **SampleFixtures**: Test samples and requests
- **IoTSensorFixtures**: Test sensors and readings
- **AlertFixtures**: Test alerts and notifications

### Data Factory
- **TestDataFactory**: Generates realistic test data
- **Randomized Values**: UUIDs, barcodes, sensor IDs
- **Temperature Simulation**: Zone-appropriate values
- **Coordinate Generation**: Realistic storage positions

## Coverage Goals

### Functional Coverage
- âœ… **Storage Operations**: 95%+ coverage
- âœ… **IoT Integration**: 90%+ coverage  
- âœ… **Health Endpoints**: 100% coverage
- ðŸ”„ **Analytics**: 85%+ coverage (in progress)
- ðŸ”„ **Automation**: 80%+ coverage (in progress)
- ðŸ”„ **Blockchain**: 90%+ coverage (in progress)

### Error Scenarios
- âœ… Validation failures
- âœ… Database constraint violations
- âœ… Capacity exceeded scenarios
- âœ… Temperature compatibility issues
- âœ… Non-existent resource access
- ðŸ”„ Network failures (in progress)
- ðŸ”„ Service unavailability (in progress)

## Best Practices

### Test Isolation
- Each test uses a separate database
- No shared state between tests
- Proper cleanup after each test
- Deterministic test data

### Performance
- Database connection pooling
- Parallel test execution where safe
- Efficient test data generation
- Minimal setup/teardown overhead

### Maintainability
- Clear test naming conventions
- Comprehensive test documentation
- Reusable test utilities
- Consistent assertion patterns

## Known Limitations

### Current Test Gaps
- Some advanced AI/ML features need more coverage
- Blockchain integration tests are basic
- Performance tests need load scenarios
- Security tests need penetration testing

### Future Enhancements
- Property-based testing with proptest
- Chaos engineering tests
- Visual regression testing
- Contract testing between services

## Contributing

### Adding New Tests
1. Choose appropriate test category (unit/integration/e2e)
2. Use existing fixtures and utilities
3. Follow naming conventions: `test_[feature]_[scenario]`
4. Include both success and failure scenarios
5. Add proper test documentation

### Test Guidelines
- Each test should be independent
- Use descriptive assertion messages
- Test edge cases and error conditions
- Keep tests fast and focused
- Document complex test scenarios

---

**Test Suite Version**: 1.0.0  
**Last Updated**: December 2024  
**Coverage Target**: 90%+ overall, 95%+ for critical paths 
