[tool:pytest]
testpaths = 
    lab_submission_rag/tests
    api_gateway/tests
    enhanced_rag_service/tests
    tests

python_files = test_*.py *_test.py
python_classes = Test*
python_functions = test_*

addopts = 
    -v
    --strict-markers
    --tb=short
    --color=yes
    --durations=10
    --maxfail=10
    --asyncio-mode=auto
    --cov=.
    --cov-report=term-missing
    --cov-report=html:test-results/coverage-html
    --cov-report=xml:test-results/coverage.xml
    --junit-xml=test-results/pytest-results.xml

filterwarnings =
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    ignore::UserWarning:chromadb.*
    ignore::UserWarning:sentence_transformers.*
    ignore::pydantic.warnings.PydanticDeprecatedSince20
    ignore::RuntimeWarning:pytest_asyncio
    ignore::UserWarning:transformers.*

markers =
    # Test Categories
    unit: Unit tests - fast, isolated component tests
    integration: Integration tests - test service interactions
    api: API endpoint tests using FastAPI TestClient or httpx
    e2e: End-to-end tests - full workflow testing
    
    # Technology-specific markers
    fastmcp: FastMCP-specific tests and server validation
    rag: RAG pipeline and document processing tests
    llm: Large Language Model interface tests
    vectorstore: Vector database and embedding tests
    gateway: API Gateway routing and proxy tests
    laboratory: Laboratory workflow and domain logic tests
    
    # Performance markers
    slow: Tests that take longer than 5 seconds
    performance: Performance benchmarking tests
    stress: High-load and stress testing
    
    # Environment markers
    requires_services: Tests requiring external services (DB, Redis, etc.)
    requires_gpu: Tests requiring GPU acceleration
    requires_internet: Tests requiring internet connectivity
    
    # AI/ML specific markers
    ai_models: Tests involving AI model inference
    document_processing: Document parsing and processing tests
    confidence_scoring: Tests related to confidence score calculation
    batch_processing: Batch operation tests

asyncio_mode = auto

# Coverage configuration
[coverage:run]
source = .
omit = 
    */tests/*
    */test_*
    */conftest.py
    */venv/*
    */.venv/*
    */env/*
    */node_modules/*
    */target/*
    */frontend/*
    */__pycache__/*
    */migrations/*
    setup.py
    */setup.py

[coverage:report]
exclude_lines =
    pragma: no cover
    def __repr__
    if self.debug:
    if settings.DEBUG
    raise AssertionError
    raise NotImplementedError
    if 0:
    if __name__ == .__main__.:
    class .*\bProtocol\):
    @(abc\.)?abstractmethod
    # Type checking imports
    if TYPE_CHECKING:
    # Debugging code
    import pdb
    pdb.set_trace()

precision = 2
show_missing = true
skip_covered = false
sort = Cover 