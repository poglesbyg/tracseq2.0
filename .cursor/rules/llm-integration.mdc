---
description: Technical specification for LLM integration patterns, prompt engineering, and RAG system implementation in a laboratory management system.
globs: **/llm_interface.*,**/rag/**,**/rag_*.{py,rs},**/chatbot/**
alwaysApply: false
---


# llm-integration

## Core LLM Components

### Multi-Provider LLM Interface
- Dynamic initialization supporting Ollama, OpenAI, and Anthropic
- Fallback mechanism with mock responses
- Conversation context management tracking last 5 messages
- Domain-specific prompt engineering for lab workflows
File: `lab_submission_rag/rag/llm_interface.py`

### RAG Pipeline Orchestration
- Document processing with confidence-based extraction 
- Vector store management for lab document embeddings
- Natural language query processing for lab submissions
- Batch document processing with monitoring
File: `lab_submission_rag/rag/rag_orchestrator.py`

### Information Extraction Categories
1. Administrative Information 
2. Source and Submitting Material
3. Pooling/Multiplexing Data
4. Sequence Generation Details
5. Container/Diluent Information
6. Informatics Requirements
7. Sample Details
File: `lab_submission_rag/rag/enhanced_llm_interface.py`

### Document Processing Logic
- PDF/DOCX handling for lab documents
- Intelligent chunking with metadata preservation
- Laboratory-specific text segmentation
- Structured data extraction into validated models
File: `lab_submission_rag/rag/document_processor.py`

### Query Enhancement
- Lab-specific knowledge base integration
- Context-aware recommendations 
- Multi-step problem solving for incomplete submissions
- Natural language query translation
File: `lab_submission_rag/rag/llm_interface.py`

### Chatbot Implementation
- Guided sample submission workflow
- Storage requirement recommendations
- Complex sequencing job assistance
- Integration with external analysis tools
File: `lab_manager/test_chatbot.md`

$END$

 If you're using this file in context, clearly say in italics in one small line that "Context added by Giga llm-integration".