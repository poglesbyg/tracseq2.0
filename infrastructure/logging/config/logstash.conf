input {
  # TCP input for direct log shipping from Rust services
  tcp {
    port => 5000
    codec => json_lines
    tags => ["rust-service"]
  }
  
  # Beats input for Filebeat
  beats {
    port => 5044
    tags => ["filebeat"]
  }
  
  # HTTP input for webhook-style logging
  http {
    port => 8080
    codec => json
    tags => ["http-logs"]
  }
}

filter {
  # Parse timestamp from Rust tracing logs
  if [timestamp] {
    date {
      match => [ "timestamp", "ISO8601" ]
      target => "@timestamp"
    }
  }
  
  # Parse Rust service logs
  if "rust-service" in [tags] {
    # Extract service name from logger field
    if [logger] {
      grok {
        match => { "logger" => "%{WORD:service_name}" }
      }
    }
    
    # Parse structured log fields
    if [level] {
      mutate {
        uppercase => [ "level" ]
      }
    }
    
    # Extract request ID for tracing
    if [request_id] {
      mutate {
        add_field => { "trace_id" => "%{request_id}" }
      }
    }
    
    # Parse laboratory-specific fields
    if [sample_id] {
      mutate {
        add_field => { "laboratory_entity" => "sample" }
        add_field => { "entity_id" => "%{sample_id}" }
      }
    }
    
    if [job_id] {
      mutate {
        add_field => { "laboratory_entity" => "job" }
        add_field => { "entity_id" => "%{job_id}" }
      }
    }
    
    if [sequencing_run_id] {
      mutate {
        add_field => { "laboratory_entity" => "sequencing_run" }
        add_field => { "entity_id" => "%{sequencing_run_id}" }
      }
    }
  }
  
  # Parse Docker container logs
  if "filebeat" in [tags] {
    # Extract container information
    if [container] {
      if [container][name] {
        mutate {
          add_field => { "container_name" => "%{[container][name]}" }
        }
      }
      
      if [container][image] {
        mutate {
          add_field => { "container_image" => "%{[container][image]}" }
        }
      }
    }
    
    # Parse JSON log messages
    if [message] {
      json {
        source => "message"
        target => "parsed_log"
      }
    }
  }
  
  # Add environment information
  mutate {
    add_field => { "environment" => "development" }
    add_field => { "system" => "tracseq" }
  }
  
  # Parse error stack traces
  if [level] == "ERROR" {
    if [message] =~ /.*stack trace.*/ {
      mutate {
        add_tag => [ "error_with_stack" ]
      }
    }
  }
  
  # Performance monitoring
  if [processing_time_ms] {
    if [processing_time_ms] > 1000 {
      mutate {
        add_tag => [ "slow_request" ]
      }
    }
  }
  
  # Security monitoring
  if [level] == "WARN" and [message] =~ /.*authentication.*|.*authorization.*|.*security.*/ {
    mutate {
      add_tag => [ "security_event" ]
    }
  }
  
  # Laboratory workflow monitoring
  if [message] =~ /.*sample.*created.*|.*job.*submitted.*|.*sequencing.*started.*/ {
    mutate {
      add_tag => [ "laboratory_workflow" ]
    }
  }
}

output {
  # Send to Elasticsearch with dynamic indexing
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "tracseq-logs-%{+YYYY.MM.dd}"
    template_name => "tracseq-logs"
    template_pattern => "tracseq-logs-*"
    template => {
      "index_patterns" => ["tracseq-logs-*"]
      "settings" => {
        "number_of_shards" => 1
        "number_of_replicas" => 0
        "refresh_interval" => "5s"
      }
      "mappings" => {
        "properties" => {
          "@timestamp" => { "type" => "date" }
          "level" => { "type" => "keyword" }
          "service" => { "type" => "keyword" }
          "logger" => { "type" => "keyword" }
          "message" => { "type" => "text" }
          "request_id" => { "type" => "keyword" }
          "trace_id" => { "type" => "keyword" }
          "laboratory_entity" => { "type" => "keyword" }
          "entity_id" => { "type" => "keyword" }
          "processing_time_ms" => { "type" => "float" }
          "container_name" => { "type" => "keyword" }
          "container_image" => { "type" => "keyword" }
          "environment" => { "type" => "keyword" }
          "system" => { "type" => "keyword" }
        }
      }
    }
  }
  
  # Send errors to separate index for alerting
  if [level] == "ERROR" {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "tracseq-errors-%{+YYYY.MM.dd}"
    }
  }
  
  # Send performance metrics to separate index
  if "slow_request" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "tracseq-performance-%{+YYYY.MM.dd}"
    }
  }
  
  # Send security events to separate index
  if "security_event" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "tracseq-security-%{+YYYY.MM.dd}"
    }
  }
  
  # Send laboratory workflow events to separate index
  if "laboratory_workflow" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "tracseq-laboratory-%{+YYYY.MM.dd}"
    }
  }
  
  # Debug output (comment out in production)
  stdout {
    codec => rubydebug
  }
} 