input {
  # TCP input for direct log shipping from Rust services
  tcp {
    port => 5000
    codec => json_lines
    tags => ["rust-service"]
  }
  
  # Beats input for Filebeat
  beats {
    port => 5044
    tags => ["filebeat"]
  }
}

filter {
  # Parse timestamp from Rust tracing logs
  if [timestamp] {
    date {
      match => [ "timestamp", "ISO8601" ]
      target => "@timestamp"
    }
  }
  
  # Parse Rust service logs
  if "rust-service" in [tags] {
    # Extract service name from logger field
    if [logger] {
      grok {
        match => { "logger" => "%{WORD:service_name}" }
      }
    }
    
    # Parse structured log fields
    if [level] {
      mutate {
        uppercase => [ "level" ]
      }
    }
    
    # Extract request ID for tracing
    if [request_id] {
      mutate {
        add_field => { "trace_id" => "%{request_id}" }
      }
    }
  }
  
  # Add environment information
  mutate {
    add_field => { "environment" => "development" }
    add_field => { "system" => "tracseq" }
  }
  
  # Parse error stack traces
  if [level] == "ERROR" {
    if [message] =~ /.*stack trace.*/ {
      mutate {
        add_tag => [ "error_with_stack" ]
      }
    }
  }
  
  # Performance monitoring
  if [processing_time_ms] {
    if [processing_time_ms] > 1000 {
      mutate {
        add_tag => [ "slow_request" ]
      }
    }
  }
  
  # Laboratory workflow monitoring
  if [message] =~ /.*sample.*created.*|.*job.*submitted.*|.*sequencing.*started.*/ {
    mutate {
      add_tag => [ "laboratory_workflow" ]
    }
  }
}

output {
  # Send to Elasticsearch with dynamic indexing
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "tracseq-logs-%{+YYYY.MM.dd}"
  }
  
  # Send errors to separate index for alerting
  if [level] == "ERROR" {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "tracseq-errors-%{+YYYY.MM.dd}"
    }
  }
  
  # Debug output for development
  stdout {
    codec => rubydebug
  }
} 